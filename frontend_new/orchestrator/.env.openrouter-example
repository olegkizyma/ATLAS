# OpenRouter Multi-Model Fallback Configuration
# Copy this to your main .env file and configure with your keys

# ===== MISTRAL (Primary LLM for Grisha) =====
MISTRAL_API_KEY=your_mistral_api_key_here
MISTRAL_MODEL=mistral-small-latest
MISTRAL_FALLBACK_MODEL=mistral-large-latest
# Optional: comma-separated list of Mistral models to try in sequence
MISTRAL_MODEL_CANDIDATES=mistral-small-latest,mistral-medium-2505,mistral-large-2411

# ===== GEMINI (Primary LLM for Atlas) =====
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-1.5-flash
# Alternative Gemini keys for rotation (optional)
GOOGLE_API_KEY=your_google_api_key_here
GENERATIVE_LANGUAGE_API_KEY=your_generative_language_api_key_here

# ===== OPENROUTER (Multi-Provider Fallback) =====
# Enable OpenRouter as final fallback when all Mistral models fail
ORCH_ENABLE_OPENROUTER_FALLBACK=true
OPENROUTER_API_KEY=sk-or-your_openrouter_api_key_here
OPENROUTER_API_URL=https://openrouter.ai/api/v1

# Optional: Override model list via CSV (takes priority over JSON file)
# OPENROUTER_MODEL_CANDIDATES=openai/gpt-4o-mini,meta/llama-3.3-70b-instruct,microsoft/phi-4

# Optional: Custom path to models JSON file
# OPENROUTER_MODELS_FILE=/path/to/custom/models.json

# ===== DEBUG =====
# Enable detailed logging for model fallback chains
DEBUG=1
